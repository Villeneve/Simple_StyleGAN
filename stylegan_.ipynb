{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6398739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers as lay\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebf8b3a",
   "metadata": {},
   "source": [
    "# Preparação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),(_,_) = keras.datasets.cifar10.load_data()\n",
    "x = (tf.cast(x[y[:,0] == 1],tf.float32)-127.5)/127.5\n",
    "batch_size = 32\n",
    "cars = tf.data.Dataset.from_tensor_slices((x)).shuffle(1000).batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7ac99",
   "metadata": {},
   "source": [
    "# Regularização R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def r1_regularization(discriminator, batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(batch)\n",
    "        logits = discriminator(batch,training=True)\n",
    "        logits = tf.reduce_sum(logits)\n",
    "    grads = tape.gradient(logits,[batch])[0]\n",
    "    norm = tf.reduce_mean(tf.reduce_sum(tf.square(grads),axis=[1,2,3]))\n",
    "    del grads\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c95a0e",
   "metadata": {},
   "source": [
    "# Declaração da Classe AdaIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class AdaIN(lay.Layer):\n",
    "    def __init__(self, channels, **kargs):\n",
    "        super().__init__(**kargs)\n",
    "        self.channels = channels\n",
    "        self.dense_gamma = lay.Dense(channels,name='Dense_Gamma')\n",
    "        self.dense_bias = lay.Dense(channels,name='Dense_Bias')\n",
    "\n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        features_map, style_w = inputs\n",
    "        gamma = self.dense_gamma(style_w)\n",
    "        bias = self.dense_bias(style_w)\n",
    "        gamma = tf.reshape(gamma,(-1,1,1,self.channels))\n",
    "        bias = tf.reshape(bias,(-1,1,1,self.channels))\n",
    "        mean, variance = tf.nn.moments(features_map,(1,2),keepdims=True)\n",
    "        normalized = tf.nn.batch_normalization(features_map,mean,variance,bias,gamma,1e-6)\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177d220",
   "metadata": {},
   "source": [
    "# Declaração da Classe StyleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae81869",
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class StyleGAN(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "        # Neurônios de conversão de z para w\n",
    "        self.mapping_network = keras.Sequential([\n",
    "            lay.InputLayer(shape=(128,)),\n",
    "            *[lay.Dense(128,activation='leaky_relu') for i in range(7)]\n",
    "            ],name='mapping_network')\n",
    "\n",
    "        # Mapa inicial\n",
    "        self.latent_map = self.add_weight(\n",
    "            (1,4,4,512),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "        # Convoluções para super-resolução\n",
    "        self.conv2d = [\n",
    "            lay.Conv2D(512,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(256,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(256,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(128,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(128,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(64,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(64,3,1,'same',activation='leaky_relu'),\n",
    "            lay.Conv2D(3,1,1,'same',activation='tanh',name='toRGB')\n",
    "        ]\n",
    "        \n",
    "        # Escaladores de ruído\n",
    "        self.noises = [\n",
    "            self.add_weight(shape=(1,1,1,512),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,512),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,256),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,256),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,128),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,128),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,64),trainable=True),\n",
    "            self.add_weight(shape=(1,1,1,64),trainable=True),\n",
    "        ]\n",
    "\n",
    "        # Camadas de Normalização de instância Adaptativa\n",
    "        self.AdaIN = [\n",
    "            AdaIN(512),\n",
    "            AdaIN(512),\n",
    "            AdaIN(256),\n",
    "            AdaIN(256),\n",
    "            AdaIN(128),\n",
    "            AdaIN(128),\n",
    "            AdaIN(64),\n",
    "            AdaIN(64),\n",
    "        ]\n",
    "\n",
    "        # Camadas de upsampling\n",
    "        self.upsampling2d = [lay.UpSampling2D() for i in range(3)]\n",
    "\n",
    "    # Quando o modelo for chamado para inferência ou treinamento, faz:\n",
    "    def call(self, z, *args, **kwargs):\n",
    "\n",
    "        batch_size = z.shape[0]\n",
    "        w = self.mapping_network(z)\n",
    "        initial_map = tf.tile(self.latent_map,(batch_size,1,1,1))\n",
    "\n",
    "        # Bloco do 4x4\n",
    "        x = initial_map + self.noises[0]*tf.random.normal((batch_size,4,4,1))\n",
    "        x = self.AdaIN[0]([x,w])\n",
    "        x = self.conv2d[0](x) + self.noises[1]*tf.random.normal((batch_size,4,4,1))\n",
    "        x = self.AdaIN[1]([x,w])\n",
    "\n",
    "        # Bloco do 8x8\n",
    "        x = self.upsampling2d[0](x)\n",
    "        x = self.conv2d[1](x) + self.noises[2]*tf.random.normal((batch_size,8,8,1))\n",
    "        x = self.AdaIN[2]([x,w])\n",
    "        x = self.conv2d[2](x) + self.noises[3]*tf.random.normal((batch_size,8,8,1))\n",
    "        x = self.AdaIN[3]([x,w])\n",
    "\n",
    "        # Bloco do 16x16\n",
    "        x = self.upsampling2d[1](x)\n",
    "        x = self.conv2d[3](x) + self.noises[4]*tf.random.normal((batch_size,16,16,1))\n",
    "        x = self.AdaIN[4]([x,w])\n",
    "        x = self.conv2d[4](x) + self.noises[5]*tf.random.normal((batch_size,16,16,1))\n",
    "        x = self.AdaIN[5]([x,w])\n",
    "\n",
    "        # Bloco do 32x32\n",
    "        x = self.upsampling2d[2](x)\n",
    "        x = self.conv2d[5](x) + self.noises[6]*tf.random.normal((batch_size,32,32,1))\n",
    "        x = self.AdaIN[6]([x,w])\n",
    "        x = self.conv2d[6](x) + self.noises[7]*tf.random.normal((batch_size,32,32,1))\n",
    "        x = self.AdaIN[7]([x,w])\n",
    "\n",
    "        x = self.conv2d[-1](x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = StyleGAN()\n",
    "\n",
    "# vgg16 = keras.applications.vgg16.VGG16(include_top=False,input_shape=(32,32,3))\n",
    "# discriminator = []\n",
    "# for layer in vgg16.layers:\n",
    "#     # if isinstance(layer,lay.Conv2D):\n",
    "#     #     discriminator.append(lay.SpectralNormalization(layer))\n",
    "#     # else:\n",
    "#     discriminator.append(layer)\n",
    "\n",
    "# discriminator = keras.Sequential([*discriminator,lay.Flatten(),lay.Dense(256,activation='leaky_relu'),lay.Dense(1,activation='sigmoid')])\n",
    "# discriminator.summary()\n",
    "\n",
    "resnet = keras.applications.resnet.ResNet50(include_top=False,input_shape=(32,32,3))\n",
    "x = lay.Flatten()(resnet.output)\n",
    "x = lay.Dense(1,activation='sigmoid')(x)\n",
    "discriminator = keras.Model(resnet.input,x)\n",
    "\n",
    "gan = [generator,discriminator]\n",
    "\n",
    "opt = [keras.optimizers.RMSprop(1e-4), keras.optimizers.RMSprop(1e-4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c746f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan,data,opt,batch_size,epoch):\n",
    "    g_loss = 0.\n",
    "    d_loss = 0.\n",
    "    for batch in data:\n",
    "        latent_z = tf.random.normal((batch_size,128))\n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            fake_imgs = gan[0](latent_z, trainable=True)\n",
    "            true_logis = gan[1](batch,trainable=True)\n",
    "            fake_logits = gan[1](fake_imgs, trainable=True)\n",
    "            g_loss = keras.losses.binary_crossentropy(tf.ones_like(fake_logits), fake_logits)# - 1e-4*tf.reduce_sum(tf.math.reduce_std(fake_imgs,axis=0))\n",
    "            d_loss = keras.losses.binary_crossentropy(tf.ones_like(true_logis),true_logis)+keras.losses.binary_crossentropy(tf.zeros_like(fake_logits),fake_logits)\n",
    "            if epoch%8 == 0:\n",
    "                d_loss += 5*r1_regularization(gan[1],batch)\n",
    "\n",
    "\n",
    "        g_grads = g_tape.gradient(g_loss,gan[0].trainable_variables)\n",
    "        opt[0].apply_gradients(zip(g_grads,gan[0].trainable_variables))\n",
    "\n",
    "        d_grads = d_tape.gradient(d_loss,gan[1].trainable_variables)\n",
    "        opt[1].apply_gradients(zip(d_grads,gan[1].trainable_variables))\n",
    "    return tf.reduce_mean(g_loss), tf.reduce_mean(d_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7325c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10001):\n",
    "    g_loss, d_loss = train_step(gan,cars,opt,batch_size,i)\n",
    "    if i%10 == 0:\n",
    "        print(f'{i} - G = {g_loss:.4f}; D = {d_loss:.4f}')\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        n = 10\n",
    "        img = gan[0](tf.random.normal((n**2,128)),training=False)\n",
    "\n",
    "        fig, ax = plt.subplots(n,n,figsize=(7,7))\n",
    "        ax = ax.ravel()\n",
    "        for ii in range(n**2):\n",
    "            ax[ii].matshow(np.uint8(img[ii]*127.5+127.5))\n",
    "            ax[ii].set_axis_off()\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.savefig(f'fig_{i}.png')\n",
    "        plt.close()\n",
    "        generator.save('style.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d98714",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "img = gan[0](tf.random.normal((n**2,128)),training=False)\n",
    "\n",
    "fig, ax = plt.subplots(n,n,figsize=(6,6))\n",
    "ax = ax.ravel()\n",
    "for i in range(n**2):\n",
    "    ax[i].matshow(np.uint8(img[i]*127.5+127.5))\n",
    "    ax[i].set_axis_off()\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
